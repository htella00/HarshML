{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "267d6fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('C:\\Python stuff\\creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73d39766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the number of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74b4d823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "#summary of the dataset, along with the number of objects that do not have null values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8e1d43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>26.0</td>\n",
       "      <td>-0.529912</td>\n",
       "      <td>0.873892</td>\n",
       "      <td>1.347247</td>\n",
       "      <td>0.145457</td>\n",
       "      <td>0.414209</td>\n",
       "      <td>0.100223</td>\n",
       "      <td>0.711206</td>\n",
       "      <td>0.176066</td>\n",
       "      <td>-0.286717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046949</td>\n",
       "      <td>0.208105</td>\n",
       "      <td>-0.185548</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.098816</td>\n",
       "      <td>-0.552904</td>\n",
       "      <td>-0.073288</td>\n",
       "      <td>0.023307</td>\n",
       "      <td>6.14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>26.0</td>\n",
       "      <td>-0.535388</td>\n",
       "      <td>0.865268</td>\n",
       "      <td>1.351076</td>\n",
       "      <td>0.147575</td>\n",
       "      <td>0.433680</td>\n",
       "      <td>0.086983</td>\n",
       "      <td>0.693039</td>\n",
       "      <td>0.179742</td>\n",
       "      <td>-0.285642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049526</td>\n",
       "      <td>0.206537</td>\n",
       "      <td>-0.187108</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.098117</td>\n",
       "      <td>-0.553471</td>\n",
       "      <td>-0.078306</td>\n",
       "      <td>0.025427</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>74.0</td>\n",
       "      <td>1.038370</td>\n",
       "      <td>0.127486</td>\n",
       "      <td>0.184456</td>\n",
       "      <td>1.109950</td>\n",
       "      <td>0.441699</td>\n",
       "      <td>0.945283</td>\n",
       "      <td>-0.036715</td>\n",
       "      <td>0.350995</td>\n",
       "      <td>0.118950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102520</td>\n",
       "      <td>0.605089</td>\n",
       "      <td>0.023092</td>\n",
       "      <td>-0.626463</td>\n",
       "      <td>0.479120</td>\n",
       "      <td>-0.166937</td>\n",
       "      <td>0.081247</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>74.0</td>\n",
       "      <td>1.038370</td>\n",
       "      <td>0.127486</td>\n",
       "      <td>0.184456</td>\n",
       "      <td>1.109950</td>\n",
       "      <td>0.441699</td>\n",
       "      <td>0.945283</td>\n",
       "      <td>-0.036715</td>\n",
       "      <td>0.350995</td>\n",
       "      <td>0.118950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102520</td>\n",
       "      <td>0.605089</td>\n",
       "      <td>0.023092</td>\n",
       "      <td>-0.626463</td>\n",
       "      <td>0.479120</td>\n",
       "      <td>-0.166937</td>\n",
       "      <td>0.081247</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>74.0</td>\n",
       "      <td>1.038370</td>\n",
       "      <td>0.127486</td>\n",
       "      <td>0.184456</td>\n",
       "      <td>1.109950</td>\n",
       "      <td>0.441699</td>\n",
       "      <td>0.945283</td>\n",
       "      <td>-0.036715</td>\n",
       "      <td>0.350995</td>\n",
       "      <td>0.118950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102520</td>\n",
       "      <td>0.605089</td>\n",
       "      <td>0.023092</td>\n",
       "      <td>-0.626463</td>\n",
       "      <td>0.479120</td>\n",
       "      <td>-0.166937</td>\n",
       "      <td>0.081247</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282987</th>\n",
       "      <td>171288.0</td>\n",
       "      <td>1.912550</td>\n",
       "      <td>-0.455240</td>\n",
       "      <td>-1.750654</td>\n",
       "      <td>0.454324</td>\n",
       "      <td>2.089130</td>\n",
       "      <td>4.160019</td>\n",
       "      <td>-0.881302</td>\n",
       "      <td>1.081750</td>\n",
       "      <td>1.022928</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.524067</td>\n",
       "      <td>-1.337510</td>\n",
       "      <td>0.473943</td>\n",
       "      <td>0.616683</td>\n",
       "      <td>-0.283548</td>\n",
       "      <td>-1.084843</td>\n",
       "      <td>0.073133</td>\n",
       "      <td>-0.036020</td>\n",
       "      <td>11.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283483</th>\n",
       "      <td>171627.0</td>\n",
       "      <td>-1.464380</td>\n",
       "      <td>1.368119</td>\n",
       "      <td>0.815992</td>\n",
       "      <td>-0.601282</td>\n",
       "      <td>-0.689115</td>\n",
       "      <td>-0.487154</td>\n",
       "      <td>-0.303778</td>\n",
       "      <td>0.884953</td>\n",
       "      <td>0.054065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287217</td>\n",
       "      <td>0.947825</td>\n",
       "      <td>-0.218773</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>0.044127</td>\n",
       "      <td>0.639270</td>\n",
       "      <td>0.213565</td>\n",
       "      <td>0.119251</td>\n",
       "      <td>6.82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283485</th>\n",
       "      <td>171627.0</td>\n",
       "      <td>-1.457978</td>\n",
       "      <td>1.378203</td>\n",
       "      <td>0.811515</td>\n",
       "      <td>-0.603760</td>\n",
       "      <td>-0.711883</td>\n",
       "      <td>-0.471672</td>\n",
       "      <td>-0.282535</td>\n",
       "      <td>0.880654</td>\n",
       "      <td>0.052808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284205</td>\n",
       "      <td>0.949659</td>\n",
       "      <td>-0.216949</td>\n",
       "      <td>0.083250</td>\n",
       "      <td>0.044944</td>\n",
       "      <td>0.639933</td>\n",
       "      <td>0.219432</td>\n",
       "      <td>0.116772</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284191</th>\n",
       "      <td>172233.0</td>\n",
       "      <td>-2.667936</td>\n",
       "      <td>3.160505</td>\n",
       "      <td>-3.355984</td>\n",
       "      <td>1.007845</td>\n",
       "      <td>-0.377397</td>\n",
       "      <td>-0.109730</td>\n",
       "      <td>-0.667233</td>\n",
       "      <td>2.309700</td>\n",
       "      <td>-1.639306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391483</td>\n",
       "      <td>0.266536</td>\n",
       "      <td>-0.079853</td>\n",
       "      <td>-0.096395</td>\n",
       "      <td>0.086719</td>\n",
       "      <td>-0.451128</td>\n",
       "      <td>-1.183743</td>\n",
       "      <td>-0.222200</td>\n",
       "      <td>55.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284193</th>\n",
       "      <td>172233.0</td>\n",
       "      <td>-2.691642</td>\n",
       "      <td>3.123168</td>\n",
       "      <td>-3.339407</td>\n",
       "      <td>1.017018</td>\n",
       "      <td>-0.293095</td>\n",
       "      <td>-0.167054</td>\n",
       "      <td>-0.745886</td>\n",
       "      <td>2.325616</td>\n",
       "      <td>-1.634651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402639</td>\n",
       "      <td>0.259746</td>\n",
       "      <td>-0.086606</td>\n",
       "      <td>-0.097597</td>\n",
       "      <td>0.083693</td>\n",
       "      <td>-0.453584</td>\n",
       "      <td>-1.205466</td>\n",
       "      <td>-0.213020</td>\n",
       "      <td>36.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1081 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "33          26.0 -0.529912  0.873892  1.347247  0.145457  0.414209  0.100223   \n",
       "35          26.0 -0.535388  0.865268  1.351076  0.147575  0.433680  0.086983   \n",
       "113         74.0  1.038370  0.127486  0.184456  1.109950  0.441699  0.945283   \n",
       "114         74.0  1.038370  0.127486  0.184456  1.109950  0.441699  0.945283   \n",
       "115         74.0  1.038370  0.127486  0.184456  1.109950  0.441699  0.945283   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "282987  171288.0  1.912550 -0.455240 -1.750654  0.454324  2.089130  4.160019   \n",
       "283483  171627.0 -1.464380  1.368119  0.815992 -0.601282 -0.689115 -0.487154   \n",
       "283485  171627.0 -1.457978  1.378203  0.811515 -0.603760 -0.711883 -0.471672   \n",
       "284191  172233.0 -2.667936  3.160505 -3.355984  1.007845 -0.377397 -0.109730   \n",
       "284193  172233.0 -2.691642  3.123168 -3.339407  1.017018 -0.293095 -0.167054   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "33      0.711206  0.176066 -0.286717  ...  0.046949  0.208105 -0.185548   \n",
       "35      0.693039  0.179742 -0.285642  ...  0.049526  0.206537 -0.187108   \n",
       "113    -0.036715  0.350995  0.118950  ...  0.102520  0.605089  0.023092   \n",
       "114    -0.036715  0.350995  0.118950  ...  0.102520  0.605089  0.023092   \n",
       "115    -0.036715  0.350995  0.118950  ...  0.102520  0.605089  0.023092   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "282987 -0.881302  1.081750  1.022928  ... -0.524067 -1.337510  0.473943   \n",
       "283483 -0.303778  0.884953  0.054065  ...  0.287217  0.947825 -0.218773   \n",
       "283485 -0.282535  0.880654  0.052808  ...  0.284205  0.949659 -0.216949   \n",
       "284191 -0.667233  2.309700 -1.639306  ...  0.391483  0.266536 -0.079853   \n",
       "284193 -0.745886  2.325616 -1.634651  ...  0.402639  0.259746 -0.086606   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "33      0.001031  0.098816 -0.552904 -0.073288  0.023307    6.14      0  \n",
       "35      0.000753  0.098117 -0.553471 -0.078306  0.025427    1.77      0  \n",
       "113    -0.626463  0.479120 -0.166937  0.081247  0.001192    1.18      0  \n",
       "114    -0.626463  0.479120 -0.166937  0.081247  0.001192    1.18      0  \n",
       "115    -0.626463  0.479120 -0.166937  0.081247  0.001192    1.18      0  \n",
       "...          ...       ...       ...       ...       ...     ...    ...  \n",
       "282987  0.616683 -0.283548 -1.084843  0.073133 -0.036020   11.99      0  \n",
       "283483  0.082926  0.044127  0.639270  0.213565  0.119251    6.82      0  \n",
       "283485  0.083250  0.044944  0.639933  0.219432  0.116772   11.93      0  \n",
       "284191 -0.096395  0.086719 -0.451128 -1.183743 -0.222200   55.66      0  \n",
       "284193 -0.097597  0.083693 -0.453584 -1.205466 -0.213020   36.74      0  \n",
       "\n",
       "[1081 rows x 31 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the rows that are duplicated\n",
    "df[df.duplicated()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fe49cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting the duplicated rows in the original dataframe\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b23866c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the number of missing values in the dataset\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a771dffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>94811.077600</td>\n",
       "      <td>47481.047891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54204.750000</td>\n",
       "      <td>84692.500000</td>\n",
       "      <td>139298.000000</td>\n",
       "      <td>172792.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>1.948026</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-0.915951</td>\n",
       "      <td>0.020384</td>\n",
       "      <td>1.316068</td>\n",
       "      <td>2.454930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>-0.004135</td>\n",
       "      <td>1.646703</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-0.600321</td>\n",
       "      <td>0.063949</td>\n",
       "      <td>0.800283</td>\n",
       "      <td>22.057729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>1.508682</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>-0.889682</td>\n",
       "      <td>0.179963</td>\n",
       "      <td>1.026960</td>\n",
       "      <td>9.382558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>-0.002966</td>\n",
       "      <td>1.414184</td>\n",
       "      <td>-5.683171</td>\n",
       "      <td>-0.850134</td>\n",
       "      <td>-0.022248</td>\n",
       "      <td>0.739647</td>\n",
       "      <td>16.875344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>1.377008</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>-0.689830</td>\n",
       "      <td>-0.053468</td>\n",
       "      <td>0.612218</td>\n",
       "      <td>34.801666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>-0.001139</td>\n",
       "      <td>1.331931</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-0.769031</td>\n",
       "      <td>-0.275168</td>\n",
       "      <td>0.396792</td>\n",
       "      <td>73.301626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>1.227664</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-0.552509</td>\n",
       "      <td>0.040859</td>\n",
       "      <td>0.570474</td>\n",
       "      <td>120.589494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>-0.000854</td>\n",
       "      <td>1.179054</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-0.208828</td>\n",
       "      <td>0.021898</td>\n",
       "      <td>0.325704</td>\n",
       "      <td>20.007208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>-0.001596</td>\n",
       "      <td>1.095492</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>-0.644221</td>\n",
       "      <td>-0.052596</td>\n",
       "      <td>0.595977</td>\n",
       "      <td>15.594995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>-0.001441</td>\n",
       "      <td>1.076407</td>\n",
       "      <td>-24.588262</td>\n",
       "      <td>-0.535578</td>\n",
       "      <td>-0.093237</td>\n",
       "      <td>0.453619</td>\n",
       "      <td>23.745136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>1.018720</td>\n",
       "      <td>-4.797473</td>\n",
       "      <td>-0.761649</td>\n",
       "      <td>-0.032306</td>\n",
       "      <td>0.739579</td>\n",
       "      <td>12.018913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>-0.000715</td>\n",
       "      <td>0.994674</td>\n",
       "      <td>-18.683715</td>\n",
       "      <td>-0.406198</td>\n",
       "      <td>0.139072</td>\n",
       "      <td>0.616976</td>\n",
       "      <td>7.848392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.995430</td>\n",
       "      <td>-5.791881</td>\n",
       "      <td>-0.647862</td>\n",
       "      <td>-0.012927</td>\n",
       "      <td>0.663178</td>\n",
       "      <td>7.126883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.952215</td>\n",
       "      <td>-19.214325</td>\n",
       "      <td>-0.425732</td>\n",
       "      <td>0.050209</td>\n",
       "      <td>0.492336</td>\n",
       "      <td>10.526766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>-4.498945</td>\n",
       "      <td>-0.581452</td>\n",
       "      <td>0.049299</td>\n",
       "      <td>0.650104</td>\n",
       "      <td>8.877742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.873696</td>\n",
       "      <td>-14.129855</td>\n",
       "      <td>-0.466860</td>\n",
       "      <td>0.067119</td>\n",
       "      <td>0.523512</td>\n",
       "      <td>17.315112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.842507</td>\n",
       "      <td>-25.162799</td>\n",
       "      <td>-0.483928</td>\n",
       "      <td>-0.065867</td>\n",
       "      <td>0.398972</td>\n",
       "      <td>9.253526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.837378</td>\n",
       "      <td>-9.498746</td>\n",
       "      <td>-0.498014</td>\n",
       "      <td>-0.002142</td>\n",
       "      <td>0.501956</td>\n",
       "      <td>5.041069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>-0.000264</td>\n",
       "      <td>0.813379</td>\n",
       "      <td>-7.213527</td>\n",
       "      <td>-0.456289</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>0.458508</td>\n",
       "      <td>5.591971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.769984</td>\n",
       "      <td>-54.497720</td>\n",
       "      <td>-0.211469</td>\n",
       "      <td>-0.062353</td>\n",
       "      <td>0.133207</td>\n",
       "      <td>39.420904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>-0.000371</td>\n",
       "      <td>0.723909</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-0.228305</td>\n",
       "      <td>-0.029441</td>\n",
       "      <td>0.186194</td>\n",
       "      <td>27.202839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.724550</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-0.542700</td>\n",
       "      <td>0.006675</td>\n",
       "      <td>0.528245</td>\n",
       "      <td>10.503090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.623702</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-0.161703</td>\n",
       "      <td>-0.011159</td>\n",
       "      <td>0.147748</td>\n",
       "      <td>22.528412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.605627</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-0.354453</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.439738</td>\n",
       "      <td>4.584549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>0.521220</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-0.317485</td>\n",
       "      <td>0.016278</td>\n",
       "      <td>0.350667</td>\n",
       "      <td>7.519589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.482053</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-0.326763</td>\n",
       "      <td>-0.052172</td>\n",
       "      <td>0.240261</td>\n",
       "      <td>3.517346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.395744</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-0.070641</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.091208</td>\n",
       "      <td>31.612198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.328027</td>\n",
       "      <td>-15.430084</td>\n",
       "      <td>-0.052818</td>\n",
       "      <td>0.011288</td>\n",
       "      <td>0.078276</td>\n",
       "      <td>33.847808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>88.472687</td>\n",
       "      <td>250.399437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>77.510000</td>\n",
       "      <td>25691.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>283726.0</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.040796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count          mean           std         min           25%  \\\n",
       "Time    283726.0  94811.077600  47481.047891    0.000000  54204.750000   \n",
       "V1      283726.0      0.005917      1.948026  -56.407510     -0.915951   \n",
       "V2      283726.0     -0.004135      1.646703  -72.715728     -0.600321   \n",
       "V3      283726.0      0.001613      1.508682  -48.325589     -0.889682   \n",
       "V4      283726.0     -0.002966      1.414184   -5.683171     -0.850134   \n",
       "V5      283726.0      0.001828      1.377008 -113.743307     -0.689830   \n",
       "V6      283726.0     -0.001139      1.331931  -26.160506     -0.769031   \n",
       "V7      283726.0      0.001801      1.227664  -43.557242     -0.552509   \n",
       "V8      283726.0     -0.000854      1.179054  -73.216718     -0.208828   \n",
       "V9      283726.0     -0.001596      1.095492  -13.434066     -0.644221   \n",
       "V10     283726.0     -0.001441      1.076407  -24.588262     -0.535578   \n",
       "V11     283726.0      0.000202      1.018720   -4.797473     -0.761649   \n",
       "V12     283726.0     -0.000715      0.994674  -18.683715     -0.406198   \n",
       "V13     283726.0      0.000603      0.995430   -5.791881     -0.647862   \n",
       "V14     283726.0      0.000252      0.952215  -19.214325     -0.425732   \n",
       "V15     283726.0      0.001043      0.914894   -4.498945     -0.581452   \n",
       "V16     283726.0      0.001162      0.873696  -14.129855     -0.466860   \n",
       "V17     283726.0      0.000170      0.842507  -25.162799     -0.483928   \n",
       "V18     283726.0      0.001515      0.837378   -9.498746     -0.498014   \n",
       "V19     283726.0     -0.000264      0.813379   -7.213527     -0.456289   \n",
       "V20     283726.0      0.000187      0.769984  -54.497720     -0.211469   \n",
       "V21     283726.0     -0.000371      0.723909  -34.830382     -0.228305   \n",
       "V22     283726.0     -0.000015      0.724550  -10.933144     -0.542700   \n",
       "V23     283726.0      0.000198      0.623702  -44.807735     -0.161703   \n",
       "V24     283726.0      0.000214      0.605627   -2.836627     -0.354453   \n",
       "V25     283726.0     -0.000232      0.521220  -10.295397     -0.317485   \n",
       "V26     283726.0      0.000149      0.482053   -2.604551     -0.326763   \n",
       "V27     283726.0      0.001763      0.395744  -22.565679     -0.070641   \n",
       "V28     283726.0      0.000547      0.328027  -15.430084     -0.052818   \n",
       "Amount  283726.0     88.472687    250.399437    0.000000      5.600000   \n",
       "Class   283726.0      0.001667      0.040796    0.000000      0.000000   \n",
       "\n",
       "                 50%            75%            max  \n",
       "Time    84692.500000  139298.000000  172792.000000  \n",
       "V1          0.020384       1.316068       2.454930  \n",
       "V2          0.063949       0.800283      22.057729  \n",
       "V3          0.179963       1.026960       9.382558  \n",
       "V4         -0.022248       0.739647      16.875344  \n",
       "V5         -0.053468       0.612218      34.801666  \n",
       "V6         -0.275168       0.396792      73.301626  \n",
       "V7          0.040859       0.570474     120.589494  \n",
       "V8          0.021898       0.325704      20.007208  \n",
       "V9         -0.052596       0.595977      15.594995  \n",
       "V10        -0.093237       0.453619      23.745136  \n",
       "V11        -0.032306       0.739579      12.018913  \n",
       "V12         0.139072       0.616976       7.848392  \n",
       "V13        -0.012927       0.663178       7.126883  \n",
       "V14         0.050209       0.492336      10.526766  \n",
       "V15         0.049299       0.650104       8.877742  \n",
       "V16         0.067119       0.523512      17.315112  \n",
       "V17        -0.065867       0.398972       9.253526  \n",
       "V18        -0.002142       0.501956       5.041069  \n",
       "V19         0.003367       0.458508       5.591971  \n",
       "V20        -0.062353       0.133207      39.420904  \n",
       "V21        -0.029441       0.186194      27.202839  \n",
       "V22         0.006675       0.528245      10.503090  \n",
       "V23        -0.011159       0.147748      22.528412  \n",
       "V24         0.041016       0.439738       4.584549  \n",
       "V25         0.016278       0.350667       7.519589  \n",
       "V26        -0.052172       0.240261       3.517346  \n",
       "V27         0.001479       0.091208      31.612198  \n",
       "V28         0.011288       0.078276      33.847808  \n",
       "Amount     22.000000      77.510000   25691.160000  \n",
       "Class       0.000000       0.000000       1.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding out the mean, standard deviation and IQR va;ues\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b29471e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of non-fraudulent transactions 283253\n",
      "The number of fraudulent transactions 473\n"
     ]
    }
   ],
   "source": [
    "#Trying to identify the imbalance in the dataset\n",
    "print(\"The number of non-fraudulent transactions\" ,len(df[df['Class']==0]))\n",
    "print(\"The number of fraudulent transactions\" ,len(df[df['Class']==1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dce55767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splitting the dataset into dependent and independent features\n",
    "x = df.drop(['Class'],axis = 1)\n",
    "x.head()\n",
    "x.shape\n",
    "y = df[\"Class\"]\n",
    "y.head()\n",
    "y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3f82235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing logistic regression without balancing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_1, Y_1, test_size =0.20, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "895a0701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performing Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74a75c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\harsh\\anaconda3\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from imbalanced-learn) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.20.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.6.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.0.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34ac0f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing undersampling on the above dataset\n",
    "from imblearn import under_sampling\n",
    "from imblearn.under_sampling import RandomUnderSampler \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a854f465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(946,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#As shown the sampling size has been decreased from 283253 to 946\n",
    "under_sampler = RandomUnderSampler()\n",
    "X_1, Y_1 = under_sampler.fit_resample(x,y)\n",
    "X_1.shape\n",
    "Y_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d022635e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1.head()\n",
    "Y_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4206b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_1, Y_1, test_size =0.20, random_state = 40)\n",
    "print(\"Precision, Recall and F1scores\\n \",classification_report(Y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9f056527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model score is  0.9410954793384053\n",
      "The model coefficient for the prediction of each target is \n",
      " [[-2.71085711e-05  7.78767171e-02 -5.14375963e-02 -4.71939607e-01\n",
      "   6.55947003e-01  3.33623241e-01 -1.68759871e-01  5.60190350e-02\n",
      "  -4.26046938e-01 -1.96574973e-01 -2.73197757e-01  7.01747463e-02\n",
      "  -4.10660846e-01 -2.60422415e-01 -8.27181514e-01 -1.82236855e-01\n",
      "  -2.46686627e-01 -2.44566906e-01  5.16770129e-02  4.35533106e-02\n",
      "  -7.56406856e-02  1.05903601e-01  2.58162643e-01 -2.92839088e-02\n",
      "   8.51374571e-03 -1.30203438e-01 -5.56797335e-02  2.71769797e-02\n",
      "   1.90406956e-02  9.29173191e-04]]\n",
      "The model intercept is \n",
      " [-0.36634268]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Performing Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"The model score is \", model.score(X_test,Y_test))\n",
    "print(\"The model coefficient for the prediction of each target is \\n\", model.coef_)\n",
    "print(\"The model intercept is \\n\", model.intercept_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "205fc752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is  0.9344760021888404\n",
      "Precision, Recall and F1scores\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94     56602\n",
      "           1       0.97      0.89      0.93     56700\n",
      "\n",
      "    accuracy                           0.93    113302\n",
      "   macro avg       0.94      0.93      0.93    113302\n",
      "weighted avg       0.94      0.93      0.93    113302\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=40).fit(X_train, Y_train)\n",
    "predict_val = model.predict(X_test)\n",
    "print(\"The accuracy score is \",accuracy_score(Y_test, predict_val))\n",
    "print(\"Precision, Recall and F1scores\\n \",classification_report(Y_test, predict_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6cdc5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model.predict(X_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "03054be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model score is  0.9210526315789473\n",
      "The model coefficient for the prediction of each target is \n",
      " [[-2.65292673e-05 -1.25184081e-02  1.78618672e-01 -7.92506333e-01\n",
      "   8.18083425e-01 -2.44596960e-03 -2.69170921e-01 -2.65025597e-01\n",
      "   4.54430768e-02 -2.59726861e-01 -4.86448126e-01  4.01983837e-01\n",
      "  -6.55452051e-01 -1.67610020e-02 -1.03656799e+00 -1.16006311e-01\n",
      "  -3.01712931e-01 -5.59274581e-01 -8.58618838e-02  4.12036339e-02\n",
      "  -5.71340872e-02  5.85108426e-02  6.70442158e-02 -8.29435778e-02\n",
      "  -1.06656552e-02 -3.66673907e-02 -3.56014120e-02  3.93272391e-02\n",
      "   1.32228031e-02  5.51615946e-04]]\n",
      "The model intercept is \n",
      " [-0.14756324]\n"
     ]
    }
   ],
   "source": [
    "print(\"The model score is \", model.score(X_test,Y_test))\n",
    "print(\"The model coefficient for the prediction of each target is \\n\", model.coef_)\n",
    "print(\"The model intercept is \\n\", model.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c27e21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix is as follows  [[91  5]\n",
      " [11 83]]\n",
      "The accuracy score is  0.9157894736842105\n",
      "Precision, Recall and F1scores\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92        96\n",
      "           1       0.94      0.88      0.91        94\n",
      "\n",
      "    accuracy                           0.92       190\n",
      "   macro avg       0.92      0.92      0.92       190\n",
      "weighted avg       0.92      0.92      0.92       190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "cm = confusion_matrix(Y_test, y_predict)\n",
    "print(\"Confusion matrix is as follows \",cm)\n",
    "print(\"The accuracy score is \",accuracy_score(Y_test, y_predict))\n",
    "print(\"Precision, Recall and F1scores\\n \",classification_report(Y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a3273996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(566506,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Oversampling the data\n",
    "from imblearn import over_sampling\n",
    "from imblearn.over_sampling import RandomOverSampler \n",
    "over_sampler = RandomOverSampler()\n",
    "X_1, Y_1 = over_sampler.fit_resample(x,y)\n",
    "X_1.shape\n",
    "Y_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148f713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1.head()\n",
    "Y_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb4323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_1, Y_1, test_size =0.20, random_state = 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2bf3c972",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performing Logistic Regression by oversampling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "y_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d4b3fc20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9157894736842105"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1c1b1b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.02021535e-05, -7.44266866e-02, -1.26693817e-02,\n",
       "        -4.98766518e-01,  8.15762575e-01,  3.86246474e-01,\n",
       "        -2.00986089e-01,  1.85390573e-01, -7.01701624e-01,\n",
       "         6.54962931e-03, -8.47359634e-02,  1.64595193e-01,\n",
       "        -1.97745735e-01, -1.10994229e-01, -1.27275753e+00,\n",
       "        -2.68464312e-01, -1.15653930e-01, -3.73066013e-01,\n",
       "        -1.71925491e-03, -1.37544971e-02, -2.03533907e-01,\n",
       "         9.01234765e-02,  4.29952028e-01, -2.55731181e-01,\n",
       "        -2.94359033e-02, -1.64512362e-01, -1.81293906e-01,\n",
       "         1.54282871e-01,  2.26562351e-02,  1.39858828e-03]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c4c0331a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.50568219])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dd9d3705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matric is as follows  [[90  6]\n",
      " [10 84]]\n",
      "The accuracy score is  0.9157894736842105\n",
      "The precision, recall and f-1scores are\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92        96\n",
      "           1       0.93      0.89      0.91        94\n",
      "\n",
      "    accuracy                           0.92       190\n",
      "   macro avg       0.92      0.92      0.92       190\n",
      "weighted avg       0.92      0.92      0.92       190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "cm = confusion_matrix(Y_test, y_predict)\n",
    "print(\"The confusion matric is as follows \",cm)\n",
    "print(\"The accuracy score is \",accuracy_score(Y_test, y_predict))\n",
    "print(\"The precision, recall and f-1scores are\\n\",classification_report(Y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2e275",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "* In the above code, we performed logistic Regression without any balancing techniques and with undersampling and oversampling.\n",
    "* As the data is highly imbalanced, in order to understand the difference balancing can make, we performed the regression without any kind of class balance, through this, we found out that the accuracy is unsually high.\n",
    "* When we balanced the weights through both, undersampling and oversampling, the accuracy came out to be 93 and 91% respectively, indicating that if class weights are imbalanced, it can affect the accuracy of the model drastically."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
